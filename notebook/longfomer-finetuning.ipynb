{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-19T16:06:46.568723Z","iopub.status.busy":"2024-04-19T16:06:46.568368Z","iopub.status.idle":"2024-04-19T16:07:39.959423Z","shell.execute_reply":"2024-04-19T16:07:39.958416Z","shell.execute_reply.started":"2024-04-19T16:06:46.568687Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import json\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n"," \n","import os\n","input_data_folder = '/kaggle/input/input-data-longformer/input_longformer'\n","input_labels_file = '/kaggle/input/coliee-24-labels-longformer/full_data_labels.json'\n","data_fulltext = {}\n","for filename in os.listdir(input_data_folder):\n","    with open(input_data_folder +  '/' + filename, 'r', encoding = 'utf-8') as f:\n","        data = json.load(f)\n","        fulltext = \"\"\n","        fulltext += data['meta'] + ' '\n","        paras = data['paragraphs']\n","        for i in range(0,len(paras)):\n","            fulltext += paras[i] + \" \"\n","        data_fulltext[filename.split('.')[0]] = fulltext\n","input_labels = {}\n","with open(input_labels_file, 'r', encoding = 'utf-8') as f:\n","    input_labels = json.load(f)\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:07:39.962223Z","iopub.status.busy":"2024-04-19T16:07:39.961697Z","iopub.status.idle":"2024-04-19T16:07:58.060874Z","shell.execute_reply":"2024-04-19T16:07:58.059879Z","shell.execute_reply.started":"2024-04-19T16:07:39.962188Z"},"trusted":true},"outputs":[],"source":["import transformers\n","import torch\n","import torch.nn as nn\n","import transformers\n","from transformers import DataCollatorForLanguageModeling\n","from transformers import LongformerModel, LongformerTokenizer\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:07:58.062894Z","iopub.status.busy":"2024-04-19T16:07:58.062120Z","iopub.status.idle":"2024-04-19T16:07:58.122307Z","shell.execute_reply":"2024-04-19T16:07:58.121409Z","shell.execute_reply.started":"2024-04-19T16:07:58.062860Z"},"trusted":true},"outputs":[],"source":["#load device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:07:58.123546Z","iopub.status.busy":"2024-04-19T16:07:58.123269Z","iopub.status.idle":"2024-04-19T16:08:17.768954Z","shell.execute_reply":"2024-04-19T16:08:17.767946Z","shell.execute_reply.started":"2024-04-19T16:07:58.123523Z"},"trusted":true},"outputs":[],"source":["list_skipped_words = ['should', 'did', 'must', 'just', '.', '..','...', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'of', 'for', 'with', 'by', 'and', 'or', 'but', 'so', 'nor', 'yet', 'from', 'into', 'onto', 'upon', 'out', 'off', 'over', 'under', 'below', 'above', 'between', 'among', 'through', 'during', 'before', 'after', 'since', 'until', 'while', 'as', 'like', 'about', 'against', 'among', 'around', 'before', 'behind', 'beneath', 'beside', 'between', 'beyond', 'during', 'inside', 'outside', 'underneath', 'within', 'without', 'throughout', 'along', 'across', 'toward', 'towards', 'up', 'down', 'forward', 'backward', 'right', 'left', 'here', 'there', 'where', 'when', 'why', 'how', 'what', 'which', 'who', 'whom', 'whose', 'whichever', 'whatever', 'whomever', 'whenever', 'wherever', 'however', 'whyever', ',', ';']\n","# load pretrained model\n","longformer_model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n","longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:17.772099Z","iopub.status.busy":"2024-04-19T16:08:17.771815Z","iopub.status.idle":"2024-04-19T16:08:17.777010Z","shell.execute_reply":"2024-04-19T16:08:17.776043Z","shell.execute_reply.started":"2024-04-19T16:08:17.772076Z"},"trusted":true},"outputs":[],"source":["longformer_model.config.output_hidden_states=True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:17.780578Z","iopub.status.busy":"2024-04-19T16:08:17.780211Z","iopub.status.idle":"2024-04-19T16:08:19.920313Z","shell.execute_reply":"2024-04-19T16:08:19.919425Z","shell.execute_reply.started":"2024-04-19T16:08:17.780555Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","class ColieeDataset(Dataset):\n","    def __init__(self, folder_path, tokenizer, max_len, labels_file, list_skipped_words,\n","                val_set):\n","        self.case_law = {}\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.labels = {}\n","        self.folder_path = folder_path\n","        self.is_val = val_set\n","        self.useless_words = set(list_skipped_words)\n","        \n","        # Đọc nhãn từ tệp và tải dữ liệu full text\n","        with open(labels_file, 'r') as f:\n","            self.labels = json.load(f)\n","        self.case_law = self.load_fulltext()\n","        train_examples, val_examples = self.split_data()\n","        if self.is_val:\n","            self.data = val_examples\n","        else:\n","            self.data = train_examples\n","\n","    def split_data(self):\n","        examples = []\n","        for key, values in self.labels.items():\n","            case_id = key\n","            for nested_case_id, _label in values.items():\n","                if case_id in self.case_law:\n","                    examples.append({\n","                        'text1': self.case_law[case_id],\n","                        'text2': self.case_law[nested_case_id],\n","                        'label': _label})\n","\n","        train_examples, val_examples = train_test_split(examples, test_size=0.2, random_state=42)\n","        train_df = pd.DataFrame(train_examples)\n","        val_df = pd.DataFrame(val_examples)\n","\n","        # Reset index \n","        train_df.reset_index(drop=True, inplace=True)\n","        val_df.reset_index(drop=True, inplace=True)\n","\n","        return train_df, val_df\n","        \n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = dict(self.data.iloc[idx])\n","        item  = self.tokenize_text_pair(item) # truncate inside\n","        item = {key: torch.tensor(val) for key, val in item.items()}\n","        return item\n","    def load_fulltext(self):\n","        _case_law = {}\n","        for filename in os.listdir(self.folder_path):\n","            with open(os.path.join(self.folder_path, filename), 'r') as f:\n","                temp_data = json.load(f)\n","                case_id = filename.split('.')[0]\n","                fulltext = temp_data['meta'] + ' '\n","                for par in temp_data['paragraphs']:\n","                    fulltext += par + ' '\n","                fulltext = self.filter_useless_words(fulltext)\n","                _case_law[case_id] = fulltext\n","        return _case_law\n","    def filter_useless_words(self, fulltext):\n","        # remove useless words in full text to make case law shorter for training\n","        words = fulltext.split()\n","        filtered_words = [word for word in words if word.lower() not in self.useless_words]\n","        return ' '.join(filtered_words)\n","    \n","    def tokenize_text_pair(self, item):\n","        inputs =  self.tokenizer(item['text1'], item['text2'], \n","                                 padding='max_length', truncation=True)\n","\n","        inputs['labels'] = torch.tensor(item['label'])\n","        return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:19.922098Z","iopub.status.busy":"2024-04-19T16:08:19.921663Z","iopub.status.idle":"2024-04-19T16:08:49.162602Z","shell.execute_reply":"2024-04-19T16:08:49.161811Z","shell.execute_reply.started":"2024-04-19T16:08:19.922066Z"},"trusted":true},"outputs":[],"source":["train_dataset = ColieeDataset(input_data_folder, longformer_tokenizer, 4096, \n","                               input_labels_file, list_skipped_words, val_set = False)\n","test_dataset = ColieeDataset(input_data_folder, longformer_tokenizer, 4096, \n","                             input_labels_file, list_skipped_words, val_set = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.163989Z","iopub.status.busy":"2024-04-19T16:08:49.163698Z","iopub.status.idle":"2024-04-19T16:08:49.169310Z","shell.execute_reply":"2024-04-19T16:08:49.168283Z","shell.execute_reply.started":"2024-04-19T16:08:49.163965Z"},"trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=6, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.171161Z","iopub.status.busy":"2024-04-19T16:08:49.170832Z","iopub.status.idle":"2024-04-19T16:08:49.191703Z","shell.execute_reply":"2024-04-19T16:08:49.190648Z","shell.execute_reply.started":"2024-04-19T16:08:49.171138Z"},"trusted":true},"outputs":[],"source":["train_dataset.__len__()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.193702Z","iopub.status.busy":"2024-04-19T16:08:49.192920Z","iopub.status.idle":"2024-04-19T16:08:49.374091Z","shell.execute_reply":"2024-04-19T16:08:49.373017Z","shell.execute_reply.started":"2024-04-19T16:08:49.193670Z"},"trusted":true},"outputs":[],"source":["train_dataset.__getitem__(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.375364Z","iopub.status.busy":"2024-04-19T16:08:49.375124Z","iopub.status.idle":"2024-04-19T16:08:49.382502Z","shell.execute_reply":"2024-04-19T16:08:49.381600Z","shell.execute_reply.started":"2024-04-19T16:08:49.375343Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, longformer_model, ffn_output_size):\n","        super(CustomModel, self).__init__()\n","        self.longformer = longformer_model\n","        self.ffn = nn.Sequential(\n","            nn.Linear(self.longformer.config.hidden_size, ffn_output_size),\n","            nn.ReLU(),\n","            nn.Linear(ffn_output_size, 2)  # Output: 0 or 1\n","        )\n","\n","    def forward(self, **inputs):\n","        longformer_output = self.longformer(\n","            **inputs\n","        )  # Last-layer hidden-state\n","        pooled_output = longformer_output.hidden_states[-1][:, 0, :]\n","#         pooled_output = longformer_output.last_hidden_state[:, 0, :]  # Take CLS token\n","        logits = self.ffn(pooled_output)\n","        return logits\n","\n","#params\n","max_len = 4096\n","batch_size = 4\n","epochs = 3\n","lr = 2e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.384447Z","iopub.status.busy":"2024-04-19T16:08:49.383830Z","iopub.status.idle":"2024-04-19T16:08:49.682138Z","shell.execute_reply":"2024-04-19T16:08:49.681336Z","shell.execute_reply.started":"2024-04-19T16:08:49.384417Z"},"trusted":true},"outputs":[],"source":["model = CustomModel(longformer_model, ffn_output_size=100)\n","model = model.to(device)\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.683439Z","iopub.status.busy":"2024-04-19T16:08:49.683159Z","iopub.status.idle":"2024-04-19T16:08:49.687939Z","shell.execute_reply":"2024-04-19T16:08:49.687051Z","shell.execute_reply.started":"2024-04-19T16:08:49.683415Z"},"trusted":true},"outputs":[],"source":["# def test():\n","#     tmp_model =  model.to(torch.device('cpu'))\n","#     text1 = 'Hello my name is DCM'\n","#     text2 = 'I'm fine thank you kinchana'\n","#     label = torch.tensor([1])\n","#     test_input_ids = longformer_tokenizer.encode_plus(\n","#         text1,\n","#         text2,\n","#         add_special_tokens=True,\n","#         max_length=4096,\n","#         truncation=True,\n","#         padding='max_length',\n","#         return_token_type_ids=True,\n","#         return_attention_mask=True,\n","#         return_tensors='pt'\n","#     )\n","\n","#     print(test_input_ids['input_ids'].shape)\n","#     print(test_input_ids['token_type_ids'].shape)\n","#     print(test_input_ids['attention_mask'].shape)\n","#     print(label.shape)\n","    \n","#     outputs = model(**test_input_ids)\n","    \n","#     print(outputs)\n","    \n","\n","# test()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.692093Z","iopub.status.busy":"2024-04-19T16:08:49.691746Z","iopub.status.idle":"2024-04-19T16:08:49.700509Z","shell.execute_reply":"2024-04-19T16:08:49.699692Z","shell.execute_reply.started":"2024-04-19T16:08:49.692063Z"},"trusted":true},"outputs":[],"source":["# train_subset = [next(iter(train_dataloader)) for _ in range(10)]\n","# test_subset = [next(iter(test_dataloader)) for _ in range(10)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:08:49.702008Z","iopub.status.busy":"2024-04-19T16:08:49.701658Z","iopub.status.idle":"2024-04-19T16:09:02.615727Z","shell.execute_reply":"2024-04-19T16:09:02.614706Z","shell.execute_reply.started":"2024-04-19T16:08:49.701978Z"},"trusted":true},"outputs":[],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:09:02.617578Z","iopub.status.busy":"2024-04-19T16:09:02.617249Z","iopub.status.idle":"2024-04-19T16:09:06.592376Z","shell.execute_reply":"2024-04-19T16:09:06.590732Z","shell.execute_reply.started":"2024-04-19T16:09:02.617547Z"},"trusted":true},"outputs":[],"source":["import logging\n","\n","# Set the logging level to WARNING\n","logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n","\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","for epoch in range(3):\n","    model.train()\n","    total_loss = 0\n","    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}', leave=False):\n","        optimizer.zero_grad()\n","        labels = batch['labels'].to(device)\n","        inputs = {\n","            'input_ids': batch['input_ids'].to(device),\n","            'attention_mask': batch['attention_mask'].to(device)\n","        }\n","        logits = model(**inputs)\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    \n","    # Validation loop\n","    model.eval()\n","    total_val_loss = 0\n","    predictions = []\n","    true_labels = []\n","    with torch.no_grad():\n","        for batch in tqdm(test_dataloader, desc=f'Validation', leave=False):\n","            labels = batch['labels'].to(device)\n","            inputs = {\n","                'input_ids': batch['input_ids'].to(device),\n","                'attention_mask': batch['attention_mask'].to(device)\n","            }\n","            logits = model(**inputs)\n","            loss = criterion(logits, labels)\n","            total_val_loss += loss.item()\n","            predictions.extend(logits.argmax(dim=1).tolist())\n","            true_labels.extend(labels.tolist())\n","    avg_val_loss = total_val_loss / len(test_dataloader)\n","    \n","    # Calculate metrics\n","    accuracy = accuracy_score(true_labels, predictions)\n","    precision = precision_score(true_labels, predictions)\n","    recall = recall_score(true_labels, predictions)\n","    f1 = f1_score(true_labels, predictions)\n","    \n","    print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n","    \n","    # Save model checkpoint\n","    checkpoint_path = os.path.join('/kaggle/working', f\"model_epoch_{epoch+1}.pt\")\n","    torch.save(model.state_dict(), checkpoint_path)\n","\n","print(\"Training finished.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:09:06.593332Z","iopub.status.idle":"2024-04-19T16:09:06.593688Z","shell.execute_reply":"2024-04-19T16:09:06.593541Z","shell.execute_reply.started":"2024-04-19T16:09:06.593527Z"},"trusted":true},"outputs":[],"source":["print('hello')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4787010,"sourceId":8105203,"sourceType":"datasetVersion"},{"datasetId":4808908,"sourceId":8135150,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
